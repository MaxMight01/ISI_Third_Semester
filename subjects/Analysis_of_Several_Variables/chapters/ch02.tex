\chapter{INTEGRATION: RIEMANN AND DARBOUX}

\section{Intuition}

\textit{September 15th.}

For the one-dimensional integration, we studied how to compute the length of curves, the area under a curve, and even antiderivatives. Our aim, now, is to extend these concepts to higher dimensions; given a function $f:O_{n} \to \R$, we want to give meaning to $\int_{O_{n}} f d\ast$, and fill the $\ast$ too.

\begin{definition}
    We term $B^{n} = \prod_{i=1}^{n} [a_{i},b_{i}]$ a \eax{closed box} in $\R^{n}$. One can show that the closure of an open box is the corresponding closed box. The \eax{volume of a box} is defined as
    \begin{align}
        v(B^{n}) = v\left( \prod_{i=1}^{n} [a_{i},b_{i}] \right) = v\left( \prod_{i=1}^{n} (a_{i},b_{i}) \right) = \prod_{i=1}^{n} (b_{i} - a_{i}).
    \end{align}
\end{definition}

We extend the concept of partitions to boxes in the natural way.

\begin{definition}
    Let $B^{n} = \prod_{i=1}^{n} [a_{i},b_{i}]$ be a closed box in $\R^{n}$. For each $i = 1,2,\ldots,n$, consider a partition of $[a_{i},b_{i}]$ give by $P_{i}:a_{i}=x_{i,0} < x_{i,1} < \cdots < x_{i,n_{i}} = n_{i}$. Set $P = P_{1} \times P_{2} \times \cdots \times P_{n}$, a \eax{partition of the box}, and set
    \begin{align}
        \Lambda(P) = \{(t_{1},t_{2},\ldots,t_{n}) : 0 \leq t_{i} \leq n_{i}\},
    \end{align}
    the set of multi-indices. For $\alpha \in \Lambda(P)$, define the $\alpha^{\text{th}}$ \eax{closed sub-box} as $B_{\alpha}^{n} = I_{1,t_{1}} \times I_{2,t_{2}} \times \cdots \times I_{n,t_{n}}$, where $I_{i,t_{i}} = [x_{i,t_{i}-1}, x_{i,t_{i}}]$. The set of all closed sub-boxes is called a \eax{partition of the box} $B^{n}$. We get
    \begin{align}
        B^{n} = \bigcup_{\alpha \in \Lambda(P)} B_{\alpha}^{n}, \quad v(B^{n}) = \sum_{\alpha \in \Lambda(P)} v(B_{\alpha}^{n}).
    \end{align}
\end{definition}

Another unavoidable definition is that of refinement of partitions.

\begin{definition}
    For a closed box $B^{n}$, a partition $\tilde{P}$ is termed a \eax{refinement} of a partition $P$ if $\tilde{P}_{i}$ is a refinement of $P_{i}$ for each $i = 1,2,\ldots,n$.
\end{definition}

Given $f \in \cB(B^{n})$, a bounded function over $B^{n}$, and a partition $P$ of $B^{n}$, we define 
\begin{align}
    m_{\alpha} = \inf_{x \in B_{\alpha}^{n}} f(x), \quad M_{\alpha} = \sup_{x \in B_{\alpha}^{n}} f(x)
\end{align}
for all $\alpha \in \Lambda(P)$. We then define the \eax{lower Darboux sum} and the \eax{upper Darboux sum} of $f$ with respect to $P$ as
\begin{align}
    L(f,P) = \sum_{\alpha \in \Lambda(P)} m_{\alpha} v(B_{\alpha}^{n}), \quad U(f,P) = \sum_{\alpha \in \Lambda(P)} M_{\alpha} v(B_{\alpha}^{n})
\end{align}
respectively. If $m = \inf_{x \in B^{n}} f(x)$ and $M = \sup_{x \in B^{n}} f(x)$, then it is easy to see that
\begin{align}
    m v(B^{n}) \leq L(f,P) \leq U(f,P) \leq M v(B^{n}).
\end{align}.

\begin{theorem}
    For $\tilde{P} \supset P$ partitions of $B^{n}$, and $f \in \cB(B^{n})$, we have
    \begin{align}
        L(f,P) \leq L(f,\tilde{P}) \leq U(f,\tilde{P}) \leq U(f,P).
    \end{align}
\end{theorem}
\begin{proof}
    The proof of this is left as an exercise to the reader; it is a straightforward generalization of the one-dimensional case.
\end{proof}
We also denote $\cP(B^{n})$ as the set of all partitions of $B^{n}$.
\begin{corollary}
    For all $P,Q \in \cP(B^{n})$, $L(f,P) \leq U(f,Q)$.
\end{corollary}
\begin{proof}
    Easy to see since $P,Q \subset P \cup Q$.
\end{proof}

Since refinement leads to an increase in the lower Darboux sum and a decrease in the upper Darboux sum, we can define as follows.
\begin{definition}
    Given $f \in cB(B^{n})$, we define the \eax{lower Darboux integral} and the \eax{upper Darboux integral} of $f$ over $B^{n}$ as
    \begin{align}
        \underline{\int_{B^{n}}} f = \sup_{P \in \cP(B^{n})} L(f,P), \quad \overline{\int_{B^{n}}} f = \inf_{P \in \cP(B^{n})} U(f,P)
    \end{align}
    respectively. If $\underline{\int_{B^{n}}} f = \overline{\int_{B^{n}}} f$, we say that $f$ is \eax{Riemann-Darboux integrable} over $B^{n}$, and denote the common value as the \eax{Darboux integral} of $f$ over $B^{n}$, denoted as
    \begin{align}
        \int_{B^{n}} f = \underline{\int_{B^{n}}} f = \overline{\int_{B^{n}}} f.
    \end{align}
    We may write
    \begin{align}
        \int_{B^{n}} f = \int_{B^{n}} f dv = \int_{B^{n}} f(x_{1},\ldots,x_{n}) dx_{1} dx_{2} \cdots dx_{n}
    \end{align}
    where $dv$ denotes the infinitesimal volume element in $n$-dimensions, and with no intention of commuting the $dx_{i}$'s; it is simply notation.
\end{definition}

Also, we denote $\cR(B^{n}) \defeq \{f \in \cB(B^{n}) : f \text{ is Riemann-Darboux integrable over } B^{n}\}$.

\begin{theorem}
    Let $f \in \cB(B^{n})$. Then $f \in \cR(B^{n})$ if and only if for every $\varepsilon > 0$, there exists a partition $P \in \cP(B^{n})$ such that $U(f,P) - L(f,P) < \varepsilon$.
\end{theorem}
\begin{proof}
    Let us assume $f$ is Riemann-Darboux integrable. Then
    \begin{align}
        \inf_{P}U(f,P) - \sup_{P}L(f,P) = \inf_{P}(U(f,P)-L(f,P)) = 0
    \end{align}
    showing the necessary result. For the converse, let $\varepsilon > 0$ be given. By hypothesis, there exists $P \in \cP(B^{n})$ such that $U(f,P) - L(f,P) < \varepsilon$. Simply by the definition of infimum and supremum, we have
    \begin{align}
        0 \leq \overline{\int_{B^{n}}} f - \underline{\int_{B^{n}}} f \leq U(f,P) - L(f,P) < \varepsilon \implies f \in \cR(B^{n}).
    \end{align}
\end{proof}

Note that $\cR(B^{n})$ is a vector space over $\R$, satisfying $\int_{B_{n}} (f + \alpha g) = \int_{B_{n}} f + \alpha \int_{B_{n}} g$ for all $f,g \in \cR(B^{n})$ and $\alpha \in \R$. Also, if $f,g \in \cR(B^{n})$ and $f(x) \leq g(x)$ for all $x \in B^{n}$, then $\int_{B^{n}} f \leq \int_{B^{n}} g$.

If $f \in \cR(B^{n})$, then $\abs{f} \in \cR(B^{n})$ and $\abs{\int_{B^{n}} f} \leq \int_{B^{n}} \abs{f}$. Also, if $f,g \in \cR(B^{n})$, then $fg \in \cR(B^{n})$, making $\cR(B^{n})$ an algebra over $\R$.

\begin{definition}
    The \eax{diameter of a box} $B^{n}$ is simply defined as the largest diagonal of the box, $\diam(B^{n})$.
\end{definition}

Using the above, the concept of mesh can be extended.
\begin{definition}
    The \eax{norm of a partition} or \eax{mesh of a partition} $P$ of a box $B^{n}$ is defined as
    \begin{align}
        \norm{P} = \max_{\alpha \in \Lambda(P)} \diam(B_{\alpha}^{n}).
    \end{align}
\end{definition}

\begin{theorem}
    $\cC(B^{n}) \subsetneq \cR(B^{n})$.
\end{theorem}
\begin{proof}
    Pick $f:B^{n} \to \R$ continuous. Given $\varepsilon > 0$, by uniform continuity, there exists $\delta > 0$ such that $\abs{f(x) - f(y)} < \frac{\varepsilon}{2v(B^{n})}$ whenever $\norm{x-y} < \delta$. Now, choose a partition $P$ of $B^{n}$ such that $\norm{P} < \delta$. Then, for each $\alpha \in \Lambda(P)$, $a_{\alpha} \in B_{\alpha}^{n}$. Thus for all $x \in B_{\alpha}^{n}$, we have
    \begin{align}
        \abs{f(x)-f(a_{\alpha})} < \frac{\varepsilon}{2v(B^{n})} = \tilde{\varepsilon} \implies f(a_{\alpha}) - \tilde{\varepsilon} < f(x) < f(a_{\alpha}) + \tilde{\varepsilon} \text{ for all } x \in B_{\alpha}^{n}.
    \end{align}
    Inserting the infimum and supremum, we get
    \begin{align}
        f(a_{\alpha}) - \tilde{\varepsilon} < m_{\alpha} \leq M_{\alpha} < f(a_{\alpha}) + \tilde{\varepsilon} \implies c(P) - \frac{\varepsilon}{2} \leq L(f,P) \leq U(f,P) \leq c(P) + \frac{\varepsilon}{2}
    \end{align}
    where $c(P) = \sum_{\alpha \in \Lambda(P)} f(a_{\alpha}) v(B_{\alpha}^{n})$. Thus $U(f,P) - L(f,P) < \varepsilon$, showing that $f \in \cR(B^{n})$.
\end{proof}

\noindent\textit{September 19th.}

We question whether the use of one-variable integration can help us in evaluating $\int_{B^{n}} f dv$ for $f \in \cR(B^{n})$. The answer is yes, and we will see how. Consider $B^{2} = [a_{1},b_{1}] \times [a_{2},b_{2}] \subseteq \R^{2}$.Given $f:B^{2} \to \R$, we consider slice functions $f_{x}:[a_{2},b_{2}] \to \R$ defined as $f_{x}(y) = f(x,y)$ for each fixed $x \in [a_{1},b_{1}]$. Similarly, one defines $f_{y}(x) = f(x,y)$ over $[a_{2},b_{2}]$. Let $P$ be a partition of $B^{2} = B_{1}^{1} \times B_{2}^{1}$, where $P = P_{1} \times P_{2}$, and $P_{i}$ is a partition of $B_{i}^{1}$ for $i=1,2$. Moreover, $\Lambda(P) = \Lambda(P_{1}) \times \Lambda(P_{2})$.

\begin{example}
    Look at $B^{2} = [0,1] \times [0,1]$ and $f(x,y) = \1_{1/2}(x) \cdot \1_{\Q}(y)$. If we consider the slice function $f_{x}:[0,1] \to \R$, then for $x = \frac{1}{2}$, $f_{\frac{1}{2}}$ is the Dirichlet function, which is not Riemann integrable. Thus, $\int_{0}^{1} \int_{0}^{1} f(x,y) dy dx$ is not defined. However, if we consider $f_{y}:[0,1] \to \R$, then for each fixed $y \in [0,1]$, $f_{y}(x)$ is $0$ except a single point, where it is $1$. Thus, $f_{y}$ is Riemann integrable for each $y \in [0,1]$, and $\int_{0}^{1} f_{y}(x) dx = 0$ along with $\int_{0}^{1} \int_{0}^{1} f(x,y) dx dy = 0$. Thus, the order of integration does not commute.

    We, however, will show that $f \in \cR(B^{2})$ and $\int_{B^{2}} f dv = 0$. Pick $\varepsilon > 0$. Pick partition $\Lambda(P_{1}) = \{0,\frac{1}{2}-\varepsilon,\frac{1}{2}+\varepsilon,1\}$ and $\Lambda(P_{2}) = \{0,1\}$. Then, $P = P_{1} \times P_{2}$ is a partition of $B^{2}$. The sub-boxes are $B_{1} = [0,\frac{1}{2}-\varepsilon] \times [0,1]$, $B_{2} = [\frac{1}{2}-\varepsilon,\frac{1}{2}+\varepsilon] \times [0,1]$, and $B_{3} = [\frac{1}{2}+\varepsilon,1] \times [0,1]$. The supremum over these boxes are $M_{1} = 0$, $M_{2} = 1$, and $M_{3} = 0$. The infimum over these boxes are $m_{1} = 0$, $m_{2} = 0$, and $m_{3} = 0$. Thus, we have
    \begin{align}
        U(f,P) - L(f,P) = \sum_{j=1}^{3} (M_{j} - m_{j}) v(B_{j}) = 2\varepsilon \to 0.
    \end{align}
    This tells us that $f \in \cR(B^{2})$and $\int_{B^{2}} f dv = 0$.
\end{example}

Now suppose $B^{m} \times B^{n} = B^{m + n} \subseteq \R^{m+n}$, and let $x \in B^{m}$ and $y \in B^{n}$. Fix $P \in \cP(B^{m+n})$ and let $P = P^{m} \times P^{n}$, where $P^{m} \in \cP(B^{m})$ and $P^{n} \in \cP(B^{n})$. Subsequently, $\Lambda(P) = \Lambda(P^{m}) \times \Lambda(P^{n})$ and for all $\alpha(P) \in \Lambda(P)$, $\alpha = (\alpha(P^{m}),\alpha(P^{n}))$. The sub-boxes are $B_{\alpha(P)}^{m+n} = B_{\alpha(P^{m})}^{m} \times B_{\alpha(P^{n})}^{n}$. Let $f:B^{m+n} \to \R$ be a bounded function, and let $f_{x} :B^{n} \to \R$ be the slice function in $x$. We then define
\begin{align}
    \underline{f}(x) \defeq \underline{\int_{B^{n}}} f_{x}(y) dv(y) \;\text{ and }\; \overline{f}(x) \defeq \overline{\int_{B^{n}}} f_{x}(y) dv(y) \;\text{ for all } x \in B^{m}.
\end{align}
which are both functions as $\underline{f},\overline{f}:B^{m} \to \R$.

\begin{theorem}[\eax{Fubini's theorem}]
    Let $f \in \cR(B^{m+n})$. Then $\underline{f},\overline{f} \in \cR(B^{m})$. Moreover,
    \begin{align}
        \int_{B^{m+n}} f dv = \int_{B^{m}} \underline{f}(x) dv(x) = \int_{B^{m}} \overline{f}(x) dv(x).
    \end{align}
\end{theorem}

\begin{proof}
    Fix $P \in \cP(B^{m} \times B^{n})$ and let $P = P^{m} \times P^{n}$, where $P^{m} \in \cP(B^{m})$ and $P^{n} \in \cP(B^{n})$. Now
    \begin{align}
        L(f,P) = \sum_{\alpha \in \Lambda(P)} m_{\alpha} v(B_{\alpha}^{m+n}) = \sum_{\alpha(P^{m}) \in \Lambda(P^{m})} \left( \sum_{\alpha(P^{n}) \in \Lambda(P^{n})} m_{(\alpha(P^{m}),\alpha(P^{n}))} v(B_{\alpha(P^{n})}^{n}) \right) v(B_{\alpha(P^{m})}^{m})
    \end{align}
    where we broke down $v(B_{\alpha}^{m+n})$ as $v(B_{\alpha(P^{m})}^{m}) v(B_{\alpha(P^{n})}^{n})$. Let us call the summation inside the parenthesis as $(\ast)$. For each $x \in B^{m}$, $\alpha(P^{n}) \in \Lambda(P^{n})$, set $m_{\alpha(P^{n})}(x) = \inf_{y \in B_{\alpha(P^{n})}^{n}} f_{x}(y)$ Thus,
    \begin{align}
        m_{\alpha(P^{n})}(x) &\geq m_{(\alpha(P^{m}),\alpha(P^{n}))} \text{ for all } x \in B_{\alpha(P^{m})}^{m} \\ \implies (\ast) &\leq \sum_{\alpha(P^{n}) \in \Lambda(P^{n})} m_{\alpha(P^{n})}(x) v(B_{\alpha(P^{n})}^{n}) = L(f_{x},P^{n}) \leq \underline{\int_{B^{n}}}f_{x}dv(x) = \underline{f}(x) \text{ for all } x \in B_{\alpha(P^{m})}^{m}.
    \end{align}
    Note, that $\underline{m}_{B_{\alpha(P^{m})}^{m}} = \inf_{x \in B_{\alpha(P^{m})}^{m}} \underline{f}(x)$ is also an upper bound for the above. Therefore, we obtain
    \begin{align}
        L(f,P) \leq \sum_{\alpha(P^{m}) \in \Lambda(P^{m})} \underline{m}_{B_{\alpha(P^{m})}^{m}} v(B_{\alpha(P^{m})}^{m}) = L(\underline{f},P^{m}).
    \end{align}
    Similarly, one obtains
    \begin{align}
        U(f,P) \geq U(\underline{f},P^{m}).
    \end{align}
    Finally, we obtain $\underline{f} \in \cR(B^{m})$. One may do the same work to obtain $\overline{f} \in \cR(B^{m})$. The equality in the theorem also follows.
\end{proof}

\begin{corollary}
    Let $f \in \cR(B^{m+n})$. If $f_{x} \in \cR(B^{n})$ for all $x \in B^{m}$ then 
    \begin{align}
        \int_{B^{m+n}} f dv = \int \int f(x,y) dv(y) dv(x).
    \end{align}
\end{corollary}

\begin{corollary}
    Let $f \in \cC(B^{n})$. Then 
    \begin{align}
        \int_{B^{n}} f dv = \int_{a_{1}}^{b_{1}} \cdots \int_{a_{n}}^{b_{n}} f(x_{1},\ldots,x_{n}) dx_{n} \cdots dx_{1}
    \end{align}
    where $B^{n} = \prod_{i=1}^{n} [a_{i},b_{i}]$, and the order of integration can be interchanged.
\end{corollary}

\textit{September 22nd.}
\begin{example}
    Let us integrate $f(x,y) = xy$ over $B^{2} = [0,1] \times [0,1]$. Since $f$ is continuous, we have
    \begin{align}
        \int_{[0,1]^{2}} f(x,y) dv = \int_{0}^{1} x\left( \int_{0}^{1}ydy \right)dx = \int_{0}^{1} x \cdot \frac{1}{2} dx = \frac{1}{4}.
    \end{align}
\end{example}

\subsection{Generalization}

So far, we have only discussed integration over boxes. We now extend this to more general sets; if $\Omega \subseteq \R^{n}$ is bounded, we wish to define $\int_{\Omega} f dv$ for $f \in \cB(\Omega)$. Here onwards, most proofs will be omitted since they involve measure theoretic arguments beyond the scope of this course. Where an idea of a proof is needed, we will provide it.

\begin{definition}
    Given $f \in \cB(\Omega)$, for some bounded $\Omega \subseteq \R^{n}$, take a box $B^{n} \supseteq \Omega$ and define $\tilde{f}:B^{n} \to \R$ as
    \begin{align}
        \tilde{f}(x) = \begin{cases}
            f(x) &\text{ if } x \in \Omega \\
            0 &\text{ if } x \in B^{n} \setminus \Omega.
        \end{cases}.
    \end{align}
    We say $f \in \cR(\Omega)$ if $\tilde{f} \in \cR(B^{n})$, and define the integral as $\int_{\Omega} f dv \defeq \int_{B^{n}} \tilde{f} dv$.
\end{definition}

\begin{theorem}
    Let $B_{1}^{n}, B_{2}^{n} \supseteq \Omega \subseteq \R^{n}$ be two boxes, with $\Omega$ bounded. Let $f \in \cB(\Omega)$ and define $\tilde{f}_{i}:B_{i}^{n} \to \R$ as above for each $i$. Then $\tilde{f}_{1} \in \cR(B_{1}^{n})$ if and only if $\tilde{f}_{2} \in \cR(B_{2}^{n})$, and in that case, $\int_{B_{1}^{n}} \tilde{f}_{1} dv = \int_{B_{2}^{n}} \tilde{f}_{2} dv$.
\end{theorem}

\begin{definition}
    A set $S \subseteq \R^{n}$ is said to be of \eax{content zero} if for every $\varepsilon > 0$ there exists a finite collection of boxes $\{B_{j}^{n}\}_{j = 1}^{m}$ such that $S \subseteq \bigcup_{j=1}^{m} B_{j}^{n}$ and $\sum_{j=1}^{m} v(B_{j}^{n}) < \varepsilon$.
\end{definition}

Note that content zero sets are \textit{not} the same as measure zero sets. For example, $\Q \cap [0,1]$ is a measure zero set but not a content zero set in $\R^{1}$. Before we discuss the consequences, let us look at two special domains.

\begin{enumerate}
    \item A set $\Omega \subseteq \R^{2}$ is $y$-simple (type-I) if there exist $\varphi_{1},\varphi_{2} \in \cB[a,b]$ such that $\Omega = \{(x,y) \mid \varphi_{1}(x) \leq y \leq \varphi_{2}(x),\; a \leq x \leq b\}$. 
    \item Similarly, $\Omega$ is $x$-simple (type-II) if there exist $\psi_{1},\psi_{2} \in \cB[c,d]$ such that $\Omega = \{(x,y) \mid \psi_{1}(y) \leq x \leq \psi_{2}(y),\; c \leq y \leq d\}$.
\end{enumerate}

\begin{theorem}
    Let $f \in \cR(\Omega)$, where $\Omega = \{(x,y) \mid \varphi_{1}(x) \leq y \leq \varphi_{2}(x),\;a \leq x \leq b\}$ for some $\varphi_{1},\varphi_{2} \in \cB[a,b]$. Suppose $\int_{\varphi_{1}(x)}^{\varphi_{2}(x)} f(x,y) dy$ exists for all $x \in [a,b]$. Then
    \begin{align}
        \int_{\Omega} f(x,y) dv = \int_{a}^{b} \int_{\varphi_{1}(x)}^{\varphi_{2}(x)} f(x,y) dy dx.
    \end{align}
\end{theorem}

\textit{September 29th.}

\begin{example}
    Let $\Omega$ be the region bounded by $y = 1$ and $y = x^{2}$. We ask to compute the integral $\int_{\Omega} x^{2}y dA$. Here, we have
    \begin{align}
        \int_{\Omega} x^{2}y dA = \int_{-1}^{1} \int_{y=x^{2}}^{1} x^{2}y dy dx = \int_{-1}^{1} \frac{1}{2}(x^{2}-x^{6}) dx = \frac{4}{21}.
    \end{align}
\end{example}

\begin{example}
    Look at $\Omega = [0,1]^{2}$ and $f(x,y) = x$ if $y \leq x^{2}$ and $y$ if $y > x^{2}$. We wish to compute $\int_{\Omega} f(x,y) dA$. We split apart region $\Omega$ into two parts, $\Omega_{1} = \{(x,y) \mid 0 \leq x \leq 1, 0 \leq y \leq x^{2}\}$ and $\Omega_{2} = \{(x,y) \mid 0 \leq x \leq 1, x^{2} < y \leq 1\}$. Then, $f|_{\Omega_{1}}(x,y) = x$ and $f|_{\Omega_{2}}(x,y) = y$. Thus,
    \begin{align}
        \int_{\Omega} f dA = \int_{\Omega_{1}} f + \int_{\Omega_{2}} f = \int_{0}^{1} \int_{y=0}^{x^{2}} x dy dx + \int_{0}^{1} \int_{y=x^{2}}^{1} y dy dx = \frac{13}{20}.
    \end{align}
\end{example}

\subsection{Change of Variables}

Recall the $n = 1$ case. Let $\varphi: O \to \R$ be a $C^{1}$-function with $O \subseteq \R$ open. Also suppose $\varphi'(x) \neq 0$ for all $x \in O$. If we let $f \in C(\varphi[a,b])$, where $[a,b] \subseteq O$, then
\begin{align}
    \int_{\varphi[a,b]} f = \int_{a}^{b} f \circ \varphi \abs{\varphi'}
\end{align}
We generalize this to higher dimensions.

\begin{theorem}
    Let $\varphi:O_{n} \to \R^{n}$ be an injective $C^{1}$-function. Suppose $\det J_{\varphi}(x) \neq 0$ for all $x \in O_{n}$. Let $\Omega \subseteq O_{n}$ be a bounded set such that $\Omega \cup \partial \Omega \subseteq O_{n}$ and $\partial \Omega$ is content zero. If $f \in \cR(\varphi(\Omega))$, then
    \begin{align}
        \int_{\varphi(\Omega)} f = \int_{\Omega} f \circ \varphi \abs{\det J_{\varphi}}.
    \end{align}
\end{theorem}
The proof of this theorem is beyond the scope of the course.

\begin{example}
    Let $(r,\theta) \in \R^{2}$. Set $x = r \cos \theta$ and $y = r \sin \theta$. Let $\varphi:\R^{2} \to \R^{2}$ be defined as $\varphi(r,\theta) = (x(r,\theta),y(r,\theta)) = (r\cos\theta,r\sin\theta)$. Here, the Jacobian is
    \begin{align}
        J_{\varphi} = \begin{bmatrix}
            \frac{\partial x}{\partial r} & \frac{\partial x}{\partial \theta} \\
            \frac{\partial y}{\partial r} & \frac{\partial y}{\partial \theta}
        \end{bmatrix} = \begin{bmatrix}
            \cos \theta & -r \sin \theta \\
            \sin \theta & r \cos \theta
        \end{bmatrix}.
    \end{align}
    Thus, $\det J_{\varphi} = r$. Set $O_{2} = \{(r,\theta) \mid r > 0, 0 < \theta < 2\pi\}$. Then, $\varphi:O_{2} \to \R^{2}$ with the same definition as above is injective and $C^{1}$ with $\det J_{\varphi}(r,\theta) \neq 0$ for all $(r,\theta) \in O_{2}$. We shall apply this in the next example.
\end{example}

\begin{example}
    We wish to compute $\int_{x^{2}+y^{2} < 1} e^{-(x^{2}+y^{2})} dA$. Set $\Omega = \{(x,y) \mid x^{2}+y^{2} < 1\}$ and $\tilde{\Omega} = \{(r,\theta) \mid 0 \leq r < 1, 0 \leq \theta < 2\pi\}$. Then, $\varphi(\tilde{\Omega}) = \Omega$. Since $\partial \tilde{\Omega}$ is content zero, we can apply the change of variables theorem. Thus,
    \begin{align}
        \int_{x^{2}+y^{2}<1} e^{-(x^{2}+y^{2})} dA = \int_{\theta = 0}^{2\pi} \int_{r=0}^{1} e^{-r^{2}} \abs{r} dr d\theta = \pi(1-e^{-1}).
    \end{align}
\end{example}

\begin{example}
    We wish to compute the area of $\Omega = \{(x,y) \mid x^{2/3} + y^{2/3} \leq 1\}$. We use the transformation $x = s \cos^{3}t$ and $y = s \sin^{3}t$. Define $\varphi:\R^{2} \to \R^{2}$ by $\varphi(s,t) = (s\cos^{3} t, s \sin^{3} t)$. Then $\Omega = \varphi([0,1] \times [0,2\pi])$. The determinant of the Jacobian is $\det J_{\varphi}(s,t) = 3s \cos^{2} t \sin^{2} t$. Thus, the area is simply
    \begin{align}
        \int_{\varphi([0,1] \times [0,2\pi])} 1 dA = \int_{0}^{2\pi} \int_{0}^{1} 3s \cos^{2} t \sin^{2} t ds dt = \frac{3\pi}{8}.
    \end{align}
    Here, even though $\det J_{\varphi}(s,t) = 0$ when $s=0$ or $t = k\pi/2$ for some integer $k$, the change of variables theorem is still applicable since these points form a content zero set.
\end{example}

\begin{example}
    We discuss spherical coordinates. In this case, we have $(x,y,z) = (r\sin\phi \cos \theta, r \sin \phi \sin \theta, r \cos \phi)$. We consider the set $O_{3} = \{(r,\theta,\phi) \mid r > 0,\; 0 < \phi < \pi,\;0 < \theta < 2\pi\}$. Define $\varphi:O_{3} \to \R^{3}$ as $\varphi(r,\theta,\phi) = (r\sin\phi \cos \theta, r \sin \phi \sin \theta, r \cos \phi)$. This $\varphi$ is a one-to-one $C^{1}$-function. The determinant of the Jacobian is $\det J_{\varphi} = r^{2} \sin \phi$, which is non-zero in $O_{3}$. Therefore, for $f \in C(\varphi([r_{1},r_{2}] \times [\phi_{1},\phi_{2}] \times [\theta_{1},\theta_{2}])) = C(\varphi(O))$ where $0 < r_{1} < r_{2}$, $0 \phi_{1} < \phi_{2} < \pi$, and $0 < \theta_{1} < \theta_{2} < 2\pi$. We then have
    \begin{align}
        \int_{\varphi(O)} f = \int_{O} f \circ \phi \cdot r^{2} \sin \phi dr d\phi d\theta.
    \end{align}
\end{example}

\section{Curves and Surfaces}

\textit{October 1st.}

\begin{definition}
    Given an interval $I = [a,b] \subseteq \R$, a parametrized \eax{curve} in $\R^{n}$ is a continuous function $\gamma:I \to \R^{n}$. We call $\{\gamma(t) \mid t \in I\}$ to be the \eax{path} of $\gamma$.
\end{definition}

For example, one may define the curve $\gamma:[0,2\pi] \to \R^{2}$ as $\gamma(t) = (\cos t, \sin t)$, which is the unit circle in $\R^{2}$. If we had chosen $\tilde{\gamma}:[0,2\pi] \to \R^{2}$ as $\tilde{\gamma}(t) = (\cos 2t, \sin 2t)$, then the path of $\tilde{\gamma}$ is still the unit circle, but it is traversed twice as fast. Thus given the path of a curve, there are infinitely many parametrizations of the same path.

\begin{definition}
    Let $\gamma:I \to \R^{n}$ be a curve. $\gamma$ is termed a $C^{1}$-function if each component function $\gamma_{i}:I \to \R$ is a $C^{1}$-function for all $i = 1,2,\ldots,n$. A differentiable $\gamma$ is called \eax{smooth} if $\gamma$ is $C^{1}$ and $\gamma'(t) \neq 0$ for all $t \in I$.
\end{definition}

\begin{definition}
    A parametrized curve $\gamma:I \to \R^{n}$ is said to be \eax{piecewise smooth} if there exists a partition of $I = [a,b]$, say, $P:a = x_{0}<x_{1}<\cdots<x_{n}=b$ such that $\gamma|_{[x_{j-1},x_{j}]}$ is smooth for all $j = 1,2,\ldots,n$.
\end{definition}

\begin{definition}
    Two parametrized curves $\gamma:[a,b] \to \R^{n}$ and $\tilde{\gamma}:[\tilde{a},\tilde{b}] \to \R^{n}$ are equivalent if there exists a strictly increasing parametrized curve $\varphi:[\tilde{a},\tilde{b}] \to [a,b]$, which is also surjective and continuously differentiable, such that $\tilde{\gamma} = \gamma \circ \varphi$.
\end{definition}

\begin{definition}
    Let $\gamma:I \to \R^{n}$ be a $C^{1}$-curve. The \eax{speed of the curve} $\gamma$ at $t \in I$ is defined as $\norm{\gamma'(t)}$. The \eax{length of the curve} $\gamma$ between $t_{1}$ and $t_{2}$ is defined as
    \begin{align}
        \int_{t_{1}}^{t_{2}} \norm{\gamma'(t)} dt
    \end{align}
    for any $[t_{1},t_{2}] \subseteq I$.
\end{definition}

Most of these definitions seem more physical rather than mathematical. A more natural way to compute the length of a curve is as follows. Given a curve $\gamma:I \to \R^{n}$, we consider a partition $P:a=t_{0} < t_{1} < t_{2} < \cdots < t_{n} = b$ of $I$. Then, we define the length of $\gamma$ with respect to $P$ as
\begin{align}
    \ell(\gamma,P) = \sum_{i=1}^{n} \norm{\gamma(t_{i})-\gamma(t_{i-1})}.
\end{align}

\begin{definition}
    A curve $\gamma:I \to \R^{n}$ is said to be \eax{rectifiable} if $\ell(\gamma) \defeq \lim_{\norm{P} \to 0} \ell(\gamma,P)$ exists.
\end{definition}

Note that for a piecewise smooth curve $\gamma:[a,b] \to \R^{n}$, the curve is rectifiable and $\ell(\gamma) = \int_{a}^{b} \norm{\gamma'(t)} dt$. However, a recetifiable curve need not be piecewise smooth. A popular example is the Cantor function.\\ \\
\textit{October 6th.}

\begin{example}
    Note that the curves $\gamma(t) = (t^{3},t^{6})$ and $\tilde{\gamma}(t) = (t,t^{2})$ for $t \in [0,1]$ have the same trace. However, one may note that $\gamma(t)$ is not smooth since $\gamma'(0) = 0$, but $\tilde{\gamma}(t)$ is smooth. Note that we had seen $\gamma = \tilde{\gamma} \circ \varphi$ is the condition for equivalent curves. But here $\varphi(t) = t^{1/3}$ is not differentiable at $t=0$. Thus, $\gamma$ and $\tilde{\gamma}$ are not equivalent.
\end{example}

\begin{example}
    Let $\gamma(t) = (\alpha t, \beta t - 16t^{2})$ with $\alpha,\beta \in \R \setminus \{0\}$. In this case, $\gamma'(t) = (\alpha,\beta-32t)$. Thus the length of $\gamma$ is $\ell(\gamma) = \int \sqrt{\alpha^{2} + (\beta-32t)^{2}} dt$ with suitable limits.
\end{example}

\begin{example}
    We look at the graph of a function $f \in \C^{1}[a,b]$. Define $\gamma:[a,b] \to \R^{2}$ as $\gamma(t) = (t,f(t))$. Then, $\gamma'(t) = (1,f'(t))$, and the length of the curve is $\ell(\gamma) = \int_{a}^{b} \sqrt{1+(f'(t))^{2}} dt$.
\end{example}

\subsection{Line Integrals}

To begin, a \eax{scalar field} is simply a function of the form $f:\R^{n} \to \R$ and a \eax{vector field} is a function of hte form $f:\R^{n} \to \R^{n}$.

Let $\gamma:[a,b] \to \R^{n}$ be a smooth (or rectifiable) curve with $C$ the trace of $\gamma$. Let $f \in \cB(C)$ be a scalar field. Given a partition $P:a = t_{0} < t_{1} < \cdots < t_{m} = b$ of $[a,b]$, we define $s_{i} \defeq \norm{\gamma(t_{i}) - \gamma(t_{i-1})}$ for all $i = 1,2,\ldots,m$. We also define $C_{i} \defeq \gamma([t_{i-1},t_{i}])$ and $M_{i} = \sup_{x \in C_{i}} f(x)$ and $m_{i} = \inf_{x \in C_{i}} f(x)$. We then define the upper and lower sums as
\begin{align}
    U(f,P) = \sum_{i=1}^{m} M_{i} s_{i} \;\text{ and }\; L(f,P) = \sum_{i=1}^{m} m_{i} s_{i}.
\end{align}

\begin{definition}
    We say that the above $f$ is integrable if
    \begin{align}
        \sup_{P \in \cP([a,b])} L(f,P) = \inf_{P \in \cP([a,b])} U(f,P) \; \left( = \int_{C} f ds\right).
    \end{align}
    The last notation is termed the \eax{line integral} of $f$ over $C$ with respect to arc length.
\end{definition}

\begin{theorem}
    The following hold.
    \begin{enumerate}
        \item If $f$ is a constant function, then $f$ is integrable over $C$.
        \item $f$ is integrable over $C$ if and only if $\lim_{\norm{P} \to 0} \sum_{i \in \Lambda(P),\;\zeta_{i} \in C_{i}} f(\zeta_{i}) s_{i}$ exists. In such a case, the limit is always equal to $\int_{C} f ds$.
        \item Let $\gamma$ be a $C^{1}$-curve and $f \in \cR(C)$. Then $f$ is integrable over $C$ and
        \begin{align}
            \int_{C} f ds = \int_{a}^{} f(\gamma(t)) \norm{\gamma'(t)} dt.
        \end{align}
    \end{enumerate}
\end{theorem}

For two equivalent parametrized curves $\gamma$ and $\tilde{\gamma} = \gamma \circ \varphi$,with $\varphi:[c,d] \to [a,b]$ differentiable, strictly increasing, and surjective, we have
\begin{align}
    \int_{c}^{d} f(\tilde{\gamma}(s)) \norm{\tilde{\gamma}'(s)} ds = \int_{c}^{d} f(\gamma(\varphi(s))) \norm{\gamma'(\varphi(s))} \varphi'(s) ds = \int_{a}^{b} f(\gamma(t)) \norm{\gamma'(t)} dt
\end{align}
where we made the change of variable $\varphi(s) \mapsto t$. Thus, the line integral is independent of the (equivalent) parametrization of the curve. We may rewrite the line integral as $\int_{\gamma} f$, for any equivalent parametrization $\gamma$ of $C$.

Let $\gamma:[a,b] \to \R^{n}$ be a piecewise smooth curve with $C$ the trace of $\gamma$. Let $f$ and $g$ be continuous scalar fields over $C$. Then, the following hold.
\begin{enumerate}
    \item $\int_{\gamma} f + \alpha g = \int_{\gamma} f + \alpha \int_{\gamma} g$ for all $\alpha \in \R$.
    \item If $f \geq g$, then $\int_{\gamma} f \geq \int_{\gamma} g$.
    \item Let $a < c < b$, and let $\gamma_{1} = \gamma|_{[a,c]}$ and $\gamma_{2} = \gamma|_{[c,b]}$. Then, $\int_{\gamma} f = \int_{\gamma_{1}} f + \int_{\gamma_{2}} f$.
    \item $\abs{\int_{\gamma} f} \leq \int_{\gamma} \abs{f}$.
    \item Given $\varepsilon > 0$, there exists $\delta > 0$ such that for all $0 < t - \tilde{t} < \delta$, we have $\int_{\gamma|_{[\tilde{t},t]}} f < \varepsilon$.
\end{enumerate}

\textit{October 8th.}

Let $F:O_{n} \to \R^{n}$ be a vector field, where $O_{n} \subseteq \R^{n}$ is open, and let $\gamma:[a,b] \to O_{n}$ be a curve. Consider a partition $P:a = t_{0} < t_{1} < \cdots < t_{m} = b$ of $[a,b]$. For each $i$, set $\gamma_{i} = \gamma(t_{i})$, and $\delta \gamma_{i} = \gamma(i) - \gamma_{i-1}$. We then define the Riemann sum as
\begin{align}
    R(F,P) = \sum_{i=1}^{m} F(\gamma_{i})\cdots \delta \gamma_{i}.
\end{align}
Finally, the line integral of $F$ over the curve $C$, the trace of $\gamma$, is defined as
\begin{align}
    \int_{C} F \cdot d\gamma = \lim_{\norm{P} \to 0} R(F,P)
\end{align}
If $\gamma$ is $C^{1}$ and $\int_{C} F \cdot d\gamma$ exists, then
\begin{align}
    \int_{C} F \cdot d\gamma = \int_{a}^{b} F(\gamma(t)) \cdot \gamma'(t) dt.
\end{align}

We now provide an analogue of the fundamental theorem of calculus for line integrals.

\begin{theorem}
    Let $f:O_{n} \to \R$ be a $C^{1}$-scalar field, and let $\gamma$ be a piecewise smooth curve joining $A$ and $B$, with $C$ the trace of $\gamma$. Then,
    \begin{align}
        \int_{C} \nabla f \cdot d\gamma = f(B) - f(A).
    \end{align}
\end{theorem}

\begin{proof}
    We have
    \begin{align}
        \int_{C} \nabla f \cdot d\gamma = \int_{a}^{b} \nabla f(\gamma(t)) \cdot \gamma'(t) dt = \int_{a}^{b} \frac{d}{dt}(f(\gamma(t))) dt = f(\gamma(b)) - f(\gamma(a)) = f(B) - f(A).
    \end{align}
\end{proof}

We move on to dealing with surfaces.

\begin{definition}
    A \eax{region} $R$ in $\R^{n}$ is a bounded open subset such that $\partial R$ is of content zero.
\end{definition}
\begin{definition}
    Let $R \subseteq \R^{2}$ be a region. A $C^{1}$-function $r:R \to \R^{3}$ is called a surface parametrization if
    \begin{enumerate}
        \item $\left\{ \frac{\partial r}{\partial u}, \frac{\partial r}{\partial v}\right\}$ is a a bounded set on $R$,
        \item $r$ is one-to-one,
        \item $r_{u} \times r_{v}|_{(u,v)} \neq 0$ for all $(u,v) \in R$.
    \end{enumerate}
    The range $S$ of $r$ is termed a parametrized \eax{surface} in $\R^{3}$.
\end{definition}

A standard example is the equation of a plane in $\R^{3}$ through $(x_{0},y_{0},z_{0})$ with normal vector $N = (a,b,c)$. This equation is given by
\begin{align}
    a(x-x_{0}) + b(y-y_{0}) + c(z-z_{0}) = 0.
\end{align}
If $c \neq 0$, then we may rewrite this as $z = z_{0} - \frac{a}{c}(x-x_{0}) - \frac{b}{c}(y-y_{0})$. Thus, we may parametrize this plane as $r(u,v) = (u,v,z_{0} - \frac{a}{c}(u-x_{0}) - \frac{b}{c}(v-y_{0}))$ for $(u,v) \in \R^{2}$.

Let us talk about the third property in the definition os a surface. Fix $(u_{0},v_{0}) \in R$. Since $R$ is open, there exists $\varepsilon > 0$ such that
\begin{align}
    (u_{0}-\varepsilon,u_{0}+\varepsilon) \times \{v_{0}\},\;\{u_{0}\} \times (v_{0}-\varepsilon,v_{0}+\varepsilon) \subseteq R.
\end{align}
Thus, we can define a map over $\varphi:(-\varepsilon,\varepsilon) \to R$ by $t \mapsto (u_{0}+t,v_{0})$, and then look at the mapping $\gamma = r \circ \varphi$, which sends $t \in (-\varepsilon,\varepsilon)$ to $r(u_{0}+t,v_{0})$. This makes $\gamma$ a curve. Therefore,

\begin{align}
    \gamma' = \frac{\partial r}{\partial u} \frac{\partial u}{\partial t} + \frac{\partial r}{\partial v} \frac{\partial v}{\partial t} = r_{u}
\end{align}
and $\gamma'(t_{0}) = r_{u}|_{(u_{0},v_{0})}$. If we work similarly for $r_{v}$, we obtain $\gamma'(t_{0}) = r_{v}|_{(u_{0},v_{0})}$. Thus, $r_{u}$ and $r_{v}$ are tangent vectors to the surface at the point $r(u_{0},v_{0})$. Since $r_{u} \times r_{v} \neq 0$, we see that $r_{u}$ and $r_{v}$ are linearly independent, and hence span the tangent plane to the surface at $r(u_{0},v_{0})$. The third property ensures that a tangent plane (and a normal vector) exists at every point on the surface.

\begin{example}
    Let $O_{2} \subseteq \R^{2}$ be a region, and let $f \in C^{1}(O_{2})$ with bounded partials. Consider the graph of $f$, which is the set $\cG(f) = \{(x,y,f(x,y)) \mid (x,y) \in O_{2}\}$. Define $r:O_{2} \to \R^{3}$ as $r(u,v) = (u,v,f(u,v))$. Then $r_{u} = (1,0,f_{u})$ and $r_{v} = (0,1,f_{v})$. Clearly, $r_{u}$ and $r_{v}$ are bounded on $O_{2}$, and $r$ is one-to-one. Finally, $r_{u} \times r_{v} = (-f_{u},-f_{v},1) \neq 0$ for all $(u,v) \in O_{2}$. Thus, $r$ is a surface parametrization and $\cG(f)$ is a parametrized surface.
\end{example}

\begin{example}
    Look at the equation of the torus given as $(x^{2}+y^{2}-a^{2})^{2}+z^{2} = b^{2}$ for some $a > b > 0$. It is left as an exercise to the reader to show that this is a parametrized surface.
\end{example}

\textit{October 13th.}

\begin{example}
    A general example of a surface is \eax{surface of revolution}. Consider a $C^{1}$-curve $t \mapsto (0,f(t),g(t)) \in \R^{3}$ for $t \in [a,b]$. Rotate this curve about the $z$-axis. The resulting surface is given as
    \begin{align}
        r(u,v) = (f(u)\cos v, f(u) \sin v, g(u))
    \end{align}
    for all $(u,v) \in [a,b] \times [0,2\pi)$. Here, $r_{u} \times r_{v} = f(u)(-g'(u) \cos v, -g'(u) \sin v, f'(u))$. To make this non-zero, one can impose several constraints; for example, $f(u) \neq 0$ for all $u \in [a,b]$.
\end{example}

\begin{example}
    The surface of a finite cylinder is parametrized as $r(u,v) = (a\cos v, a \sin v, u)$ for $(u,v) \in [0,b] \times [0,2\pi)$ for some $a,b > 0$. One can verify that $r_{u} \times r_{v} \neq 0$ for all $(u,v)$. Note that this is a surface of revolution with $f(u) = a$ and $g(u) = u$.
\end{example}

\subsection{Tangent Plane and Normal}

Let $r:R \to \R^{3}$ be a parametrized surface and let $S$ be the range of $r$. Fix a point $P = r(u_{0},v_{0}) \in S$.

\begin{definition}
    $T_{P}S$ is defined to be the vector space `generated' by $r_{u}(P)$ and $r_{v}(P)$. This is termed the \eax{tangent plane} of $S$ at $P$. Formally,
    \begin{align}
        T_{P}S = \{ \vec{r}_{0} + t_{1}r_{u}(P) + t_{2}r_{v}(P) \mid t_{1},t_{2} \in \R\}
    \end{align}
\end{definition}

\begin{example}
    Consider the graph function $z = f(x,y)$ for $(x,y) \in O_{2} \subseteq \R^{2}$ open. Then $r(u,v) = (u,v,f(u,v))$ is the graph function. Here, $r_{u} \times r_{v} = (-f_{u},-f_{v},1)$. Fix $P = (a,b,f(a,b))$. Then the tangent plane at $P$ is given by
    \begin{align}
        -f_{u}(a,b)(x-a) - f_{v}(a,b)(y-b) + (z-f(a,b)) = 0
    \end{align}
    and the equation of the normal is
    \begin{align}
        \frac{x-a}{-f_{u}(a,b)} = \frac{y-b}{-f_{v}(a,b)} = \frac{z-f(a,b)}{1}.
    \end{align}
\end{example}

\begin{example}
    Equation of the tangent plane and normal to $z = \frac{2x}{y} - x^{2}$ at $(1,1,1)$; here the partials are
    \begin{align}
        \frac{\partial z}{\partial x} = \frac{2}{y} - 2x,\; \text{ and }\; \frac{\partial z}{\partial y} = -\frac{2x}{y^{2}}.
    \end{align}
    The normal vector at $(1,1,1)$ is $(0,2,1)$. Thus the equation of the normal is
    \begin{align}
        \frac{x-1}{0} = \frac{y-1}{2} = \frac{z-1}{1}
    \end{align}
    and the equation of the tangent plane is $2(y-1) + (z-1) = 0$.
\end{example}

\begin{remark}
    Consider the graph function $\{(x,y,f(x,y)) \mid (x,y) \in O_{2}\}$. Recalling the tangent plane from before, we can approximate $f(x,y)$ near $(a,b)$ as
    \begin{align}
        f(x,y) \approx f(a,b) + f_{x}(a,b)(x-a) + f_{y}(a,b)(y-b).
    \end{align}
\end{remark}

\begin{example}
    Let us approximate $(1.99)^{2} - \frac{1.99}{1.01}$ using the above method. Clearly a suitable function is $z = x^{2}-\frac{x}{y}$ and a suitable point is $(2,1)$. Here, $f(2,1) = 2$, $f_{x}(x,y) = 2x - \frac{1}{y}$ and $f_{y}(x,y) = \frac{x}{y^{2}}$. Thus, $f_{x}(2,1) = 3$ and $f_{y}(2,1) = 2$. Therefore,
    \begin{align}
        f(x,y) \approx 2 + 3(x-2) + 2(y-1)
    \end{align}
    for points $(x,y)$ near $(2,1)$. Setting $x = 1.99$ and $y = 1.01$, we get $f(1.99,1.01) \approx 1.99$. The actual value is $1.9898$.
\end{example}

Our goal, now, is to compute the area of surfaces. In the most simple case, a parallelogram in $\R^{3}$ with sides $\vec{u}_{0}$ and $\vec{v}_{0}$. The area of such a surface is simply $\norm{\vec{u}_{0} \times \vec{v}_{0}}$. Now consider the surface $\{(x,y,ax+by+c) \mid (x,y) \in B^{2}\}$. The area of this surface is simply $\sqrt{1+a^{2}+b^{2}} \cdot \text{area}(B^{2}) = \norm{r_{x} \times r_{y}} \cdot \text{area}(B^{2})$. This is because the normal vector to this surface is $(-a,-b,1)$, and hence the area of the parallelogram formed by $(1,0,a)$ and $(0,1,b)$ is $\sqrt{1+a^{2}+b^{2}}$.

Let $S$ be the range of $r$ where $r:B^{2} \to \R^{3}$ is a parametrized surface. Write
\begin{align}
    B^{2} = \bigcup_{\alpha \in \Lambda(P)} B_{\alpha}^{2}
\end{align}
where $P$ is a partition of $B_{2}$ and $B_{\alpha}^{2}$ are small rectangles. Pick $x_{\alpha} \in \intr(B_{\alpha}^{2})$ for all $\alpha \in \Lambda(P)$. Then the approximate are of $S$ induced by $P$ is given as
\begin{align}
    \sum_{\alpha \in \Lambda(P)} \norm{r_{u}(x_{\alpha}) \times r_{v}(x_{\alpha})} \cdot \text{area}(B_{\alpha}^{2}).
\end{align}
The area of the surface $S$ is then defined to be the limit of the above expression as $\norm{P} \to 0$, provided the limit exists. Thus this limit, for a parametrized curve $r:R \to \R^{3}$, is equal to
\begin{align}
    \int_{R} \norm{r_{u} \times r_{v}} dA.
\end{align}
\begin{example}
    Let $f \in C^{1}(R)$, for $R \subseteq \R^{2}$ a region.
    Consider $r:R \to \R^{3}$ defined as $r(u,v) = (u,v,f(u,v))$. Therefore the area of the graph of $f$ over $R$ is given as
    \begin{align}
        \int_{R}\sqrt{f_{u}^{2} + f_{v}^{2} + 1} dA.
    \end{align}
\end{example}

\textit{October 14th.}

\begin{example}
    We compute the area of the surface parametrized by $r(x,y) = (\cos x, \sin x, y)$ on the region $0 \leq x \leq \pi/2$ and $0 \leq y \leq 1$. Here $r_{x} = (-\sin x, \cos x, 0)$ and $r_{y} = (0,0,1)$. Thus $r_{x} \times r_{y} = (\cos x, \sin x, 0)$ and $\norm{r_{x} \times r_{y}} = 1$. Therefore the area is simply $\int_{0}^{\pi/2} \int_{0}^{1} 1 dy dx = \pi/2$.
\end{example}

\begin{example}
    We compute the area of the unit hemisphere. In spherical coordinates, the region we're dealing with is $R = \{(u,v) \in \R^{2} \mid 0 < u,v < \pi\}$ and the parametrization is $r(u,v) = (\sin u \cos v, \sin u \sin v, \cos u)$ for all $(u,v) \in R$. Here $\norm{r_{u} \times r_{v}} = \abs{\sin u}$. Thus the area of the surface is
    \begin{align}
        \int_{R} \sin u dA = 2\pi.
    \end{align}
\end{example}

So far, we have computed the line integral of both scalar and vector fields. We have also computed the area of surfaces. We now move on to computing the surface integral of scalar and vector fields.

\begin{definition}
    Let $S \subseteq O_{3}$ be a surface in an open set $O_{3} \subseteq \R^{3}$. Let $f \in C(O_{3})$. As in the area computation,
    \begin{align}
        \lim_{\norm{P} \to 0} \sum_{\alpha \in \Lambda(P),\;x_{\alpha} \in B_{\alpha}^{2}} f(r(x_{\alpha})) \norm{r_{u}(x_{\alpha}) \times r_{v}(x_{\alpha})} \cdot \text{area}(B_{\alpha}^{2}) = \int_{R} f \circ r \norm{r_{u} \times r_{v}} dA.
    \end{align}
    The \eax{surface integral} of $f$ over $S$ is defined to be the above limit, provided it exists. The notation for this is
    \begin{align}
        \int_{S} f ds = \int_{R} f \circ r \norm{r_{u} \times r_{v}} dA.
    \end{align}
\end{definition}

One can verify that for a reparametrization $\tilde{r}$ such that $r = \tilde{r} \circ \varphi$ for a continuously differentiale bijective $\varphi$, the surface integral remains unchanged over the new region $\tilde{R}$ and
\begin{align}
    \int_{R} f \circ r \norm{r_{u} \times r_{v}} dA = \int_{\tilde{R}} f \circ \tilde{r} \norm{\tilde{r}_{u} \times \tilde{r}_{v}} dA.
\end{align}

\begin{example}
    For a surface given by $z = \sqrt{x^{2}+y^{2}}$ for $0 \leq z \leq 1$, let us compute $\int_{S} (x^{2}+y^{2}+z^{2}) ds$. A parametrization is $r(x,y) = (x,y,\sqrt{x^{2}+y^{2}})$ for $(x,y) \in R = \{(x,y) \mid x^{2}+y^{2} \leq 1\}$. Noting that $r_{u} = \frac{x}{\sqrt{x^{2}+y^{2}}}$ and $r_{v} = \frac{y}{\sqrt{x^{2}+y^{2}}}$, we have
    \begin{align}
        \int_{S} (x^{2}+y^{2}+z^{2}) ds = \int_{R} (x^{2}+y^{2}+(x^{2}+y^{2})) \norm{r_{u} \times r_{v}} dA = 2\sqrt{2} \int_{R} \sqrt{x^{2}+y^{2}} dA = \sqrt{2} \pi.
    \end{align}
\end{example}

We now define the surface integral of a vector field.

\begin{definition}
    A surface $S \subseteq \R^{3}$ is oriented if there exists a continuous vector field $\vec{n}:S \to \R^{3}$ such that $\vec{n}(x)$ is a unit normal vector to the tangent plane $T_{x}S$ for all $x \in S$.
\end{definition}

Such an orientation is called a \eax{normal field}.As an example, the M\"obius strip is not orientable, but the sphere is orientable.

\begin{definition}
    The surface integral of a vector field $\vec{F}:S \to \R^{3}$ over an oriented surface $S$ with orientation $\vec{n}$ is defined as
    \begin{align}
        \int_{S} \vec{F} \cdot d\vec{s} \defeq \int_{S} \vec{F} \cdot \vec{n} ds
    \end{align}
\end{definition}

\textit{October 24th.}

\begin{example}
    Let $S$ be the unit sphere $\{x \in \R^{3} \mid \norm{x} = 1\}$. Here, the normal field $\vec{n}(x) = x$ for all $x \in S$ works.
\end{example}

\begin{example}
    Let $S$ be the graph of $f$ as $\{(x,y,f(x,y)) \mid (x,y) \in O_{2}\}$. Here $r:O_{2} \to \R^{3}$ given by $r(x,y) = (x,y,f(x,y))$ is a parametrization of $S$. Note that $r_{x} \times r_{y} = (-f_{x},-f_{y},1)$. Thus, a normal field is given by
    \begin{align}
        \eta = \frac{(-f_{x},-f_{y},1)}{\sqrt{1+f_{x}^{2}+f_{y}^{2}}}.
    \end{align}
    For this to be continuous, we need $f \in C^{1}(O_{2})$.
\end{example}

The integral defined as before is also termed as \eax{flux} of the vector field $\vec{F}$ across the surface $S$. In general, computing flux is difficult but we still have some special cases.

\begin{remark}
    Suppose $\vec{n} = \frac{r_{u} \times r_{v}}{\norm{r_{u} \times r_{v}}}$ is a normal field on $S$. Then, the integration is simplified as
    \begin{align}
        \int_{S} \vec{F} \cdot d\vec{s} = \int_{S} \vec{F} \cdot \vec{n} ds = \int_{R} \left( \vec{F} \cdot \frac{r_{x} \times r_{y}}{\norm{r_{x} \times r_{y}}} \right) \norm{r_{x} \times r_{y}} dA = \int_{R} \vec{F} \cdot (r_{x} \times r_{y}) dA.
    \end{align}
\end{remark}

\begin{example}
    Suppose the vector field is $\vec{F}(x,y,z) = (x,y,z)$ on $S$ which is the range of $r$ defined as $r(x,y) = (\cos x, \sin x, y)$ for $(x,y) \in [0,\pi/2] \times [0,1]$. This surface is the quarter unit cylinder as discussed before. In this case, $r_{x} \times r_{y} = (\cos x, \sin x, 0)$ and $\norm{r_{x} \times r_{y}} = 1$. Thus the normal field is $\vec{n} = (\cos x, \sin x, 0)$. Thus,
    \begin{align}
        \int_{S} \vec{F} \cdot d\vec{s} = \int_{R} (\cos x, \sin x, y) \cdot (\cos x, \sin x, 0) dA = \int_{R} dA = \frac{\pi}{2}.
    \end{align}
\end{example}

Recall that in the line integral version of the fundamental theorem of calculus, we had
\begin{align}
    \int_{C} \nabla f \cdot d\gamma = f(B) - f(A)
\end{align}
where $f:O_{n} \to \R$ is a $C^{1}$-scalar field and $\gamma$ is a piecewise smooth curve joining $A$ and $B$ with $C$ the trace of $\gamma$. If $C$ is close, then $\int_{C} \nabla f \cdot d\gamma = 0$.

\begin{definition}
    A vector field $\vec{F}:O_{n} \to \R^{n}$ is \eax{conservative} if $\vec{F} = \nabla f$ for some $C^{1}$-scalar field $f:O_{n} \to \R$. The function $f$ is called a \eax{potential function} for $\vec{F}$.
\end{definition}

Let $F:O_{n} \to \R^{n}$ be a vector field, where $O_{n}$ is also connected. Then the following are equivalent.
\begin{enumerate}
    \item $F$ is conservative.
    \item $\int_{C} \vec{F} \cdot d\vec{r} = 0$ for all closed piecewise smooth curves $C$ in $O_{n}$.
    \item $\int_{C_{1}} \vec{F} \cdot d\vec{r} = \int_{C_{2}} \vec{F} \cdot d\vec{r}$ for all piecewise smooth curves $C_{1}$ and $C_{2}$ in $O_{n}$ with the same endpoints.
\end{enumerate}

We now ask whether given a vector field $\vec{F}:O_{n} \to \R^{n}$, is it always conservative? Input $F = (P,Q,R)$. If $F$ is conservative, then $F = \nabla f$ for, assume, some $C^{2}$-function $f$, or $(P,Q,R) = (f_{x},f_{y},f_{z})$. In this case,
\begin{align}
    \frac{\partial P}{\partial y} - \frac{\partial Q}{\partial x} = 0,\quad \frac{\partial P}{\partial z} - \frac{\partial R}{\partial x} = 0,\quad \frac{\partial Q}{\partial z} - \frac{\partial R}{\partial y} = 0.
\end{align}
These conditions are equivalent to saying that the \eax{curl} of $\vec{F}$ is zero, where the curl is defined as
\begin{align}
    \nabla \times F = \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z} \right) \times (P,Q,R) = 0.
\end{align}

\begin{example}
    Suppose $F(x,y) = (xy,1-x^{2})$. Extending to $\R^{3}$ as $F(x,y,z) = (xy,1-x^{2},0)$, we compute the curl as
    \begin{align}
        \nabla \times F = (0,0,-3x) \neq 0.
    \end{align}
    Thus, $F$ is not conservative.
\end{example}

\begin{example}
    Let $F(x,y) = (y-3,x+2) = (P,Q)$ for all $(x,y) \in \R^{2}$. Here, $\frac{\partial P}{\partial y} - \frac{\partial Q}{\partial x} = 1 -1 = 0$. This implies that the curl is zero, but the vector field may still not be conservative. If possile, let $F$ be conservative with potential function $f:\R^{2} \to \R$ being $C^{2}$. Then $f_{x} = y-3$ and $f_{y} = x+2$. Integrating $f_{x}$ with respect to $x$, we get $f(x,y) = xy - 3x + \varphi(y)$. Differentiating with respect to $y$, we get $f_{y} = x + \varphi'(y)$. Equating this to $x+2$, we get $\varphi'(y) = 2$, or $\varphi(y) = 2y + c$ for some constant $c \in \R$. Thus, a potential function is given as $f(x,y) = xy - 3x + 2y + c$. Therefore, $F$ is conservative.
\end{example}

The above example can be generalized; a vector field $F$ defined on a convex domain with continuous partials and zero curl is always conservative.

\begin{example}
    Suppose $F(x,y) = (-\frac{y}{x^{2}+y^{2}}, \frac{x}{x^{2}+y^{2}})$ for all $(x,y) = \R^{2}\setminus (0,0)$. Then $\frac{\partial P}{\partial y} - \frac{\partial Q}{\partial x} = 0$. This domain is not convex. Consider the curve $C$ parametrized as $r(\theta) = (\cos \theta, \sin \theta)$ for $\theta \in [0,2\pi]$. Then,
    \begin{align}
        \int_{C} \vec{F} \cdot d\vec{r} = \int_{0}^{2\pi} \left( -\frac{\sin \theta}{1}, \frac{\cos \theta}{1} \right) \cdot (-\sin \theta, \cos \theta) d\theta = \int_{0}^{2\pi} 1 d\theta = 2\pi \neq 0.
    \end{align}
    This tells us that $F$ is not conservative. Note here that $C$ was a closed curve \textit{wrapping} around the origin, which was excluded from the domain of $F$.
\end{example}

A following theorem provides an answer to the question of when a vector field is conservative.

\begin{definition}
    Let $\cD$ be an open and connected subset of $\R^{2}$. We say $\cD$ is \eax{simply connected} if whenever $C \subseteq \cD$ is a simple closed curve, $C$ can be shrunk continuously to a point inside $\cD$.
\end{definition}