\chapter{RECURRENCE RELATIONS AND GENERATING FUNCTIONS}

\section{Generating Functions}
\textit{August 7th.}

We begin with ordinary ones.

\begin{definition}
    For a sequence $(a_{n})_{n \geq 0} \subseteq \R$, the \eax{ordinary generating function} associated with this sequence is defined as
    \begin{align}
        f(x) = \sum_{n=0}^{\infty} a_{n} x^{n} = a_{0} + a_{1}x + a_{2}x^{2} + \cdots.
    \end{align}
\end{definition}
Note that we are not concerned with convergence right now. We deconstruct our abstraction of ideas into levels, starting with the first level as regarding ordinary generating functions as algebraic objects. One can multiply and add them to create new generating functions. The second level is regarding them as analytic objects, only if the radius of convergence is positive. 

The above is known as \eax{Z-transform}, where a sequence is mapped onto a function. When using the word transform, we generally mean a `change of basis'; in this case, we are changing from a sequence space to a function space.

\begin{definition}
    For a sequence $(a_{n})_{n \geq 0} \subseteq \R$, the \eax{exponential generating function} associated with this sequence is defined as
    \begin{align}
        f(x) = \sum_{n=0}^{\infty} \frac{a_{n}}{n!} x^{n} = a_{0} + a_{1}x + \frac{a_{2}}{2!}x^{2} + \cdots.
    \end{align}
\end{definition}

Again, we have transformed from a sequence space to a function space. One can also transform from a random variable space to a function space.

\begin{definition}
    For a random variable $X$ taking values in $\R$, the \eax{moment generating function} associated with this random variable is defined as
    \begin{align}
        M_{X}(t) = E[e^{tX}] = \sum_{n=0}^{\infty} \frac{E[X^{n}]}{n!} t^{n} = 1 + E[X]t + \frac{E[X^{2}]}{2!}t^{2} + \cdots.
    \end{align}
\end{definition}

\subsection{Algberaic Operaions}
We give a kind of correspondence between algebraic operations and combinatorial interpretations.
\begin{enumerate}
    \item Multiplying by $x^{k}$ maps $a_{0}+a_{1}x+a_{2}x^{2}+\cdots$ to $a_{0}x^{k}+a_{1}x^{k+1}+a_{2}x^{k+2}+\cdots$. This corresponds to shifting the sequence $(a_{0},a_{1},\ldots)$ right by $k$ places. This is known as the \eax{shift operator}.
    \item Multiplication is also defined; for two functions $a_{0}+a_{1}x+a_{2}x^{2}+\cdots$ and $b_{0}+b_{1}x+b_{2}x^{2}+\cdots$, their product is given by $a_{0}+(a_{1}b_{0}+a_{0}b_{1})x+(a_{2}b_{0}+a_{1}b_{1}+a_{0}b_{2})x^{2}+\cdots$. This corresponds to combining objects of size $k$ and size $n-k$ chosen independently.
    \item Differentiation maps $a_{0}+a_{1}x+a_{2}x^{2}+\cdots$ to $a_{1}+2a_{2}x+3a_{3}x^{2}+\cdots$. This corresponds to weighing the sequence values by their index, with a shift of one place to the right.
\end{enumerate}

\begin{example}
    Suppose we have $k$ boxes labelled $1$ through $k$, and box $i$ contains $r_{i}$ balls for $1 \leq i \leq k$. We wish to encode all possible configurations in a kind of book-keeping device. For a particular $(r_{1},\ldots,r_{k})$, we have
    \begin{align}
        \sum_{r_{i}\geq 0} x_{1}^{r_{1}} \cdots x_{k}^{r_{k}} = (1+x_{1}+x_{1}^{2}+\cdots)(1+x^{2}+x_{2}^{2}+\cdots)\cdots(1+x_{k}+x_{k}^{2}+\cdots).
    \end{align}
    We find the number of partitions of $n$ (balls) into $k$ numbers (boxes), where each number if non-negative. Disregarding the order, we set all the $x_{i}$'s equal to each other. Thus, we wish to find the coefficient of $x^{n}$ where $r_{1}+\cdots+r_{k} = n$. From the sum above, we have
    \begin{align}
        (1+x+x^{2}+\cdots)^{k} = (1-x)^{-k} = \sum_{j=0}^{\infty} \binom{k-1+j}{j} x^{j} x^{j}.
    \end{align}
    Therefore, the required coefficient is $\binom{k-1+n}{n}$.
\end{example}

We briefly introduce the idea of rings. A \eax{ring} $(R,+,\ast)$ is a set $R$ with two operations $+$ and $\ast$ such that $(R,+)$ is an abelian group, $(R,\ast)$ is a monoid, and the distributive law holds. Some examples of rings include $\Z$, $M_{n}(\C)$, and $\C[x]$. Another example is the ring of formal power series $\C[[x]]$, which consists of all series of the form $a_{0}+a_{1}x+a_{2}x^{2}+\cdots$ where $a_{i} \in \C$. We ask which elements of this ring are invertible.

We claim that $a_{0}+a_{1}x+a_{2}x^{2}+\cdots$ is invertible if and only if $a_{0} \neq 0$. We find $b_{0}+b_{1}x+b_{2}x^{2}+\cdots$ such that
\begin{align}
    (a_{0}+a_{1}x+a_{2}x^{2}+\cdots)(b_{0}+b_{1}x+b_{2}x^{2}+\cdots) = 1.
\end{align}
This first gives us $a_{0}b_{0} = 1$, so $b_{0} = \frac{1}{a_{0}}$. The next term gives us $a_{0}b_{1}+a_{1}b_{0} = 0$, so $b_{1} = -\frac{a_{1}}{a_{0}^{2}}$. Continuing this process, we find that the coefficients of $b$ can be expressed in terms of the coefficients of $a$ as
\begin{align}
    b_{n} = -\frac{1}{a_{0}} \sum_{k=1}^{n} a_{k}b_{n-k}.
\end{align}
There is also the ring homomorphism $\ev_{z}:\C[[x]] \to \C$ where $x \mapsto z$, with $z \in \C$.

\begin{example}
    Let $d_{n}$ denote the number of derangements of $\{1,2,\ldots,n\}$. We consider a derangement $\Pi$ of $\{1,2,\ldots,n+1\}$ where
    \begin{itemize}
        \item Case I: $\Pi(n+1) = i$ and $\Pi(i) = n+1$ for some $i$. The number of such derangements is $nd_{n-1}$.
        \item Case II: $\Pi(n+1) = i$ and $\Pi(j) = n+1$ for some $i \neq j$. The number of such derangements is $d_{n+1} = nd_{n}$.
    \end{itemize}
    Thus, the total number of derangements is $d_{n+1} = n(d_{n}+d_{n-1})$.
    Here, $d_{0} = 1$, $d_{1} = 0$, and $d_{2} = 1$. The exponential generating function, here, is
    \begin{align}
        D(x) = \sum_{n=0}^{\infty} d_{n} \frac{x^{n}}{n!} \implies D'(x) = \sum_{n=1}^{\infty} nd_{n} \frac{x^{n-1}}{(n-1)!} = \sum_{n=0}^{\infty} d_{n+1} \frac{x^{n}}{n!} = \sum_{n=1}^{\infty} \frac{d_{n}}{(n-1)!} x^{n} + \sum_{n=1}^{\infty} \frac{d_{n-1}}{(n-1)!} x^{n}.
    \end{align}
    This gives us
    \begin{align}
        D'(x) = xD'(x) + xD(x) \implies \frac{D'(x)}{D(x)} = \frac{x}{1-x} \implies D(x) = C \left( \frac{e^{-x}}{1-x} \right).
    \end{align}
    Plugging in $x = 0$ givens $C = 1$. Thus, the exponential generating function is
    \begin{align}
        D(x) = \frac{e^{-x}}{1-x} = (1+x+x^{2}+x^{3}+\cdots)(1-x+\frac{x^{2}}{2!}-\frac{x^{3}}{3!}+\cdots).
    \end{align}
    The coefficient of $x^{n}$ in the above series is $\frac{d_{n}}{n!}$, giving us
    \begin{align}
        d_{n} = n! \sum_{k=0}^{n} a_{k}b_{n-k} = n! \left( 1-\frac{1}{1!}+\frac{1}{2!} + \cdots + (-1)^{n}\frac{1}{n!} \right).
    \end{align}
\end{example}

% Recall the identity $\sum_{i=0}^{n} (-1)^{i} \binom{n}{i} \binom{m+n-i}{k-i}$ which was $\binom{m}{k}$ for $m \geq k$ and $0$ for $m < k$.

\begin{example}
    Suppose we wish to find number of ways to make $n$ change with the denominations $1$, $2$, and $5$. We use generating functions. Thus,
    \begin{align}
        (1+x+x^{2}+\cdots)(1+x^{2}+x^{4}+\cdots)(1+x^{5}+x^{10}+\cdots) = \frac{1}{(1-x)(1-x^{2})(1-x^{5})}.
    \end{align}
    From above, taking the $n^{\text{th}}$ derivative of the fraction,dividng it by $n!$, and evaluating at $x = 0$ provides the number of ways to make change for $n$.
\end{example}

\subsection{Extended Binomial Theorem}
\textit{August 8th.}

We begin by extending the definition of a binomial coefficient.

\begin{definition}
    For any $u \in \R$ and positive integer $k$, we define the \eax{extended binomial coefficient} as
    \begin{align}
        \binom{u}{k} = \frac{u(u-1)(u-2) \cdots (u-k+1)}{k!}
    \end{align}
    with $\binom{u}{0} = 1$.
\end{definition}

\begin{theorem}
    For positive integers $n$ and $r$, we have
    \begin{align}
        \binom{-n}{r} = (-1)^{r} \binom{n+r-1}{r}.
    \end{align}
\end{theorem}
\begin{proof}
    We simply have
    \begin{align}
        \binom{-n}{r} = (-1)^{r} \frac{n(n+1) \cdots (n+r-1)}{r!} = (-1)^{r} \binom{n+r-1}{r}.
    \end{align}
\end{proof}
\begin{theorem}[The \eax{extended binomial theorem}]
    For any $u \in \R$ and positive integer $k$, we have
    \begin{align}
        (1+x)^{u} = \sum_{k=0}^{\infty} \binom{u}{k} x^{k}.
    \end{align}.
\end{theorem}

The extended binomial theorem helps to compute coefficients of generating functions such like $\frac{1}{(1+x)^{5}}$ or even $\sqrt{1+x}$.

\begin{example}
    We compute the coefficient of $x^{2026}$ in the generating function $G(x) = \frac{1}{(1-x)^{2}(1+x)^{2}}$. We break down as partial fractions to get
    \begin{align}
        G(x) &= \frac{1}{(1-x)^{2}(1+x)^{2}} = \frac{1}{4} \left( \frac{1}{1-x} + \frac{1}{(1-x)^{2}} + \frac{1}{1+x} + \frac{1}{(1+x)^{2}} \right) \\ &= \frac{1}{4} \sum_{k=0}^{\infty} \left((-1)^{k} \binom{-1}{k}+(-1)^{k} \binom{-2}{k} + \binom{-1}{k} + \binom{-2}{k}\right) x^{k}.
    \end{align}
    The odd terms vanish, so we set $k$ to be even to get the coefficient of $x^{k}$ as
    \begin{align}
        \frac{1}{4} \left( 2\binom{-1}{k}+2\binom{-2}{k}\right) = 1 + \frac{k}{2}.
    \end{align}
    Setting $k = 2026$ gives the desired solution of $1014$.
\end{example}

\subsection{Bernoulli Numbers}

\begin{definition}
    In power series of $\frac{t}{e^{t}-1} = \sum_{k=0}^{\infty} B_{k} \frac{t^{k}}{k!}$, the coefficients $B_{k}$ are known as the \eax{Bernoulli numbers}.
\end{definition}

Here, $B_{0}$ is defined to be $1$. One can also recursively define them as $B_{0} = 1$ and $B_{j}$ for $j \geq 1$ such that $\sum_{k=0}^{n} \binom{n+1}{k} B_{k} = 0$ for $n \geq 1$

One also has a useful formula for the Bernoulli numbers.

\begin{theorem}[\eax{Faulhaber's formula}]
    We have
    \begin{align}
        \sum_{m=1}^{n} m^{k} = \frac{1}{k+1} \sum_{j=0}^{k} \binom{k+1}{j} B_{j} n^{k+1-j}.
    \end{align}
\end{theorem}

Setting $k = 1$, we get
\begin{align}
    1 +2 + \cdots + n = \frac{1}{2} \left(\binom{2}{0}B_{0}(n+1)^{2} + \binom{2}{1}B_{1}(n+1) \right) = \frac{1}{2} \left( (n+1)^{2} - (n+1) \right) = \frac{1}{2}(n+1)n.
\end{align}
Similarly, one may verify for $k = 2$ or $k = 3$.

\begin{proof}
    To this end, we use the \eax{Bernoulli polynomials} $B_{k}$ which are interpreted as coefficients in
    \begin{align}
        \frac{te^{xt}}{e^{t}-1} = \sum_{k=0}^{\infty} B_{k}(x) \frac{t^{k}}{k!}
    \end{align}
    with $B_{k}(0) = B_{k}$. We claim that $B_{n}(x) = \sum_{k=0}^{n} \binom{n}{k} B_{k} x^{n-k}$. We have
    \begin{align}
        \frac{t}{e^{t}-1} e^{xt} = \left( \sum_{k=0}^{\infty} B_{k} \frac{t^{k}}{k!} \right)e^{xt} = \sum_{n=0}^{\infty} \left( \sum_{k=0}^{\infty} \binom{n}{k} B_{k} x^{n-k} \right) \frac{t^{n}}{n!}.
    \end{align}
    Summing gives us $\dfrac{t(e^{nt}-1)}{(e^{t}-1)^{2}}$
    \begin{align}
        = \sum_{m=0}^{n-1} \frac{te^{mt}}{e^{t}-1} &= \frac{t}{e^{t}-1}\sum_{m=0}^{n-1} (1+mt+m^{2}\frac{t^{2}}{2!}+\cdots) = \frac{t}{e^{t}-1}\left( n + \sum_{m=0}^{n-1} m \frac{t}{1!} + \cdots + \sum_{m=0}^{n-1} m^{k} \frac{t^{k}}{k!} + \cdots \right) \notag \\
        \implies \frac{t(e^{nt}-1)}{e^{t}-1} &= \frac{te^{nt}}{e^{t}-1} - \frac{t}{e^{t}-1} = \sum_{k=0}^{\infty} (B_{n}(x)-B_{k}(0)) \frac{t^{k}}{k!} = t \left( n + (\cdots) \right).
    \end{align}
    Matching the terms gives us
    \begin{align}
        1 + 2^{k} + \cdots + n^{k} = \frac{1}{k+1} \left( B_{k+1}(n+1)-B_{k+1}(0) \right) = \frac{1}{k+1} \left( \sum_{j=0}^{k+1} B_{j}(n+1)^{k-j} \right) - B_{k+1}(0).
    \end{align}
\end{proof}

\section{The Pigeonhole Principle}
\textit{August 12th.}

The \eax{pigeonhole principle} simply states that if there are $N$ objects places into $k$ boxes, then some box contains at least $\ceil{\frac{N}{k}}$ objects.

\begin{proof}
    Assume, if possible, that every box has less than $\ceil{\frac{N}{k}}$ objects. Then the total number of objects is at most $k \cdot \ceil{\frac{N}{k}}$. We take cases.
    \begin{itemize}
        \item Case I, where $k \mid N$. Then $\frac{N}{k}$ is a positive integer, and the total number of objects is less than $k \cdot \frac{N}{k} = N$. This is a contradiction.
        \item Case II, where $k \nmid N$. Then every box has at most $\floor{\frac{N}{k}}$ objects, which is less than $\frac{N}{k}$. Multiplying by $k$ tell us that the total number of objects is less than $k \cdot \frac{N}{k}$ which is, again, a contradiction.
    \end{itemize}
\end{proof}

\begin{theorem}[The \eax{Erd\"os-Szekeres theorem}]
    Any sequence of $mn+1$ distinct real numbers either contains an increasing subsequence of length $n+1$ or a decreasing subsequence of length $m+1$.
\end{theorem}

\begin{proof}
    Suppose the sequence of numbers is $a_{1},a_{2},\ldots,a_{mn+1}$. Assign a pair of numbers $(b_{i},c_{i})$ to each index $i$, where $b_{i}$ is the length of the longest increasing subsequence starting at $i$ and $c_{i}$ is the length of the longest decreasing subsequence starting at $i$.

    If $b_{i} \geq n + 1$ for some $i$, or if $c_{i} \geq m + 1$ for some $i$, we are done. Else, we have $b_{i} \leq n$ and $c_{i} \leq m$ for all $i$. Since both are less than or equal to their respective bounds, the most number of distinct pairs $(b_{i},c_{i})$ is $mn$. Thus, by the pigeonhole principle, there exists some $i \neq j$ such that $(b_{i},c_{i}) = (b_{j},c_{j})$. Without loss of generality, assume $i < j$.
    \begin{itemize}
        \item Case I, where $a_{i} < a_{j}$. Then $a_{i}$ can be (pre)appended to any increasing sequence starting at $a_{j}$ which is a contradiction since $b_{i} > b_{j}$.
        \item Case II, where $a_{i} > a_{j}$. Then $a_{i}$ can be (pre)appended to any decreasing sequence starting at $a_{j}$ which is a contradiction since $c_{i} > c_{j}$.
    \end{itemize}
\end{proof}

\eax{Dirichlet's principle} states that in any set of $n+1$ integers, two of them must leave the same remainder modulo $n$. This is easy to see since there are only $n$ possible remainders (namely $0, 1, \ldots, n-1$) and $n+1$ integers. By the pigeonhole principle, at least two of the integers must fall into the same remainder class.